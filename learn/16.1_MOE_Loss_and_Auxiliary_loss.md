# Auxiliary Losses and Load Balancing in Mixture of Experts

## Table of Contents
1. [Introduction to the Problem](#introduction-to-the-problem)
2. [Load Balancing Loss (Detailed)](#load-balancing-loss-detailed)
3. [Importance Loss](#importance-loss)
4. [Router Z-Loss](#router-z-loss)
5. [Combining Multiple Losses](#combining-multiple-losses)
6. [Metrics for MoE](#metrics-for-moe)
7. [Implementation Guide](#implementation-guide)
8. [Practical Examples](#practical-examples)
9. [Debugging Load Imbalance](#debugging-load-imbalance)

---

## Introduction to the Problem

### Why Do We Need Auxiliary Losses?

In Mixture of Experts, the **primary objective** is to minimize the task loss (e.g., cross-entropy for language modeling):

$$\mathcal{L}_{\text{task}} = -\sum_{i} y_i \log(\hat{y}_i)$$

However, the **routing mechanism** can develop pathological behaviors:

**Problem 1: Load Imbalance**
```
Expert 0: ████████████████████████ 85% of tokens
Expert 1: ███ 10% of tokens
Expert 2: █ 3% of tokens
Expert 3: █ 2% of tokens
```
- Most tokens go to one expert
- Other experts are undertrained
- Wasted capacity

**Problem 2: Routing Collapse**
```
Initially:  Expert usage is balanced
After 100 steps: All tokens → Expert 0
After 200 steps: Expert 0 dominates completely (positive feedback loop)
```
- One expert gets slightly better
- Router sends it more tokens
- Gets even better gradients
- Cycle continues → collapse

**Problem 3: Dead Experts**
```
Training starts: All experts active
After training: Experts 2, 5, 7, 11 never selected
Result: Wasted parameters
```

**Solution: Auxiliary Losses**

Add extra loss terms that **explicitly encourage balanced routing**:

$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \alpha \cdot \mathcal{L}_{\text{balance}} + \beta \cdot \mathcal{L}_{\text{importance}} + \gamma \cdot \mathcal{L}_{\text{z}}$$

---

## Load Balancing Loss (Detailed)

### Original Formulation (Shazeer et al., 2017)

**Goal**: Encourage each expert to receive approximately equal number of tokens.

**Mathematical Definition**:

$$\mathcal{L}_{\text{balance}} = \text{num\_experts} \times \sum_{i=1}^{E} f_i \times P_i$$

where:
- $E$ = number of experts
- $f_i$ = fraction of tokens dispatched to expert $i$
- $P_i$ = mean router probability for expert $i$

### Understanding the Components

**Component 1: Fraction of Tokens ($f_i$)**

$$f_i = \frac{1}{N} \sum_{j=1}^{N} \mathbb{1}[\text{expert}_j = i]$$

where:
- $N$ = total number of tokens in batch
- $\mathbb{1}[\text{expert}_j = i]$ = 1 if token $j$ is routed to expert $i$, else 0

**Example**:
```
Batch: 32 tokens
Expert 0 receives: 15 tokens → f_0 = 15/32 = 0.469
Expert 1 receives: 10 tokens → f_1 = 10/32 = 0.313
Expert 2 receives: 5 tokens  → f_2 = 5/32 = 0.156
Expert 3 receives: 2 tokens  → f_3 = 2/32 = 0.063
```

**Component 2: Mean Router Probability ($P_i$)**

$$P_i = \frac{1}{N} \sum_{j=1}^{N} g_{ij}$$

where:
- $g_{ij}$ = router probability (gate value) for token $j$ and expert $i$

**Example**:
```
Token 0: [0.6, 0.2, 0.1, 0.1] ← Expert 0 gets 0.6
Token 1: [0.4, 0.3, 0.2, 0.1] ← Expert 0 gets 0.4
...
Token 31: [0.5, 0.3, 0.15, 0.05]

P_0 = (0.6 + 0.4 + ... + 0.5) / 32 = 0.45
P_1 = (0.2 + 0.3 + ... + 0.3) / 32 = 0.30
P_2 = (0.1 + 0.2 + ... + 0.15) / 32 = 0.15
P_3 = (0.1 + 0.1 + ... + 0.05) / 32 = 0.10
```

### Why This Formula Works

**Ideal case (perfect balance)**:

$$f_i = P_i = \frac{1}{E} \text{ for all } i$$

Then:

$$\mathcal{L}_{\text{balance}} = E \times \sum_{i=1}^{E} \frac{1}{E} \times \frac{1}{E} = E \times E \times \frac{1}{E^2} = 1$$

**Imbalanced case**:

If expert 0 dominates: $f_0 = 0.8, P_0 = 0.7$

$$\mathcal{L}_{\text{balance}} \geq E \times (0.8 \times 0.7 + \text{small terms}) = E \times (0.56 + ...) > 1$$

**Proof that minimum is at perfect balance**:

Given constraint $\sum_i f_i = \sum_i P_i = 1$

Using Cauchy-Schwarz inequality:

$$\sum_{i=1}^{E} f_i P_i \geq \frac{1}{E}$$

with equality when $f_i = P_i = \frac{1}{E}$ for all $i$.

### Step-by-Step Computation

**Input**: 
- Router logits: $H \in \mathbb{R}^{N \times E}$ (N tokens, E experts)
- Top-k expert assignments

**Step 1: Compute router probabilities**

$$G = \text{softmax}(H) \in \mathbb{R}^{N \times E}$$

$$G_{ij} = \frac{\exp(H_{ij})}{\sum_{k=1}^{E} \exp(H_{ik})}$$

**Step 2: Compute $P_i$ (average probability)**

$$P_i = \frac{1}{N} \sum_{j=1}^{N} G_{ji}$$

In code:
```python
P = gates.mean(dim=0)  # Average over all tokens
```

**Step 3: Compute $f_i$ (fraction dispatched)**

For top-k routing:

$$f_i = \frac{1}{N} \sum_{j=1}^{N} \mathbb{1}[i \in \text{TopK}(\mathbf{h}_j)]$$

In code:
```python
# top_k_indices: (N, k) array of selected expert indices
f = torch.zeros(num_experts)
for i in range(num_experts):
    # Count how many tokens selected expert i (in any top-k position)
    f[i] = (top_k_indices == i).any(dim=-1).float().mean()
```

**Step 4: Compute loss**

$$\mathcal{L}_{\text{balance}} = E \times \sum_{i=1}^{E} f_i \times P_i$$

In code:
```python
load_balance_loss = num_experts * torch.sum(f * P)
```

### Numerical Example

**Setup**:
- 4 experts (E=4)
- 8 tokens (N=8)
- Top-2 routing (k=2)

**Router probabilities** (after softmax):
```
Token 0: [0.7, 0.2, 0.05, 0.05]
Token 1: [0.6, 0.25, 0.1, 0.05]
Token 2: [0.1, 0.6, 0.2, 0.1]
Token 3: [0.05, 0.7, 0.15, 0.1]
Token 4: [0.15, 0.1, 0.65, 0.1]
Token 5: [0.1, 0.1, 0.6, 0.2]
Token 6: [0.05, 0.1, 0.2, 0.65]
Token 7: [0.1, 0.05, 0.15, 0.7]
```

**Top-2 selections**:
```
Token 0: [0, 1]  ← Expert 0 and 1
Token 1: [0, 1]
Token 2: [1, 2]
Token 3: [1, 2]
Token 4: [2, 3]
Token 5: [2, 3]
Token 6: [3, 2]
Token 7: [3, 2]
```

**Compute $P_i$**:
```
P_0 = (0.7 + 0.6 + 0.1 + 0.05 + 0.15 + 0.1 + 0.05 + 0.1) / 8 = 0.231
P_1 = (0.2 + 0.25 + 0.6 + 0.7 + 0.1 + 0.1 + 0.1 + 0.05) / 8 = 0.263
P_2 = (0.05 + 0.1 + 0.2 + 0.15 + 0.65 + 0.6 + 0.2 + 0.15) / 8 = 0.263
P_3 = (0.05 + 0.05 + 0.1 + 0.1 + 0.1 + 0.2 + 0.65 + 0.7) / 8 = 0.244
```

**Compute $f_i$**:
```
Expert 0: Selected in tokens [0, 1] → f_0 = 2/8 = 0.25
Expert 1: Selected in tokens [0, 1, 2, 3] → f_1 = 4/8 = 0.50
Expert 2: Selected in tokens [2, 3, 4, 5, 6, 7] → f_2 = 6/8 = 0.75
Expert 3: Selected in tokens [4, 5, 6, 7] → f_3 = 4/8 = 0.50
```

**Note**: Sum is 2.0 because each token selects 2 experts!

**Normalize $f_i$** (for top-k, divide by k):
```
f_0 = 0.25 / 2 = 0.125
f_1 = 0.50 / 2 = 0.25
f_2 = 0.75 / 2 = 0.375
f_3 = 0.50 / 2 = 0.25
```

Now sum is 1.0 ✓

**Compute loss**:
```
L_balance = 4 × (0.125×0.231 + 0.25×0.263 + 0.375×0.263 + 0.25×0.244)
          = 4 × (0.0289 + 0.0658 + 0.0986 + 0.0610)
          = 4 × 0.2543
          = 1.017
```

**Interpretation**: Very close to 1.0 (ideal), so routing is quite balanced!

---

## Importance Loss

### Motivation

Load balancing loss addresses **how many tokens** go to each expert.

But what if expert probabilities are high, but still imbalanced?

**Example**:
```
Expert 0: Selected 50% of time, average probability = 0.9
Expert 1: Selected 50% of time, average probability = 0.3
```

Both get same number of tokens, but Expert 0 has much higher confidence!

**Importance loss** ensures experts are **similarly important** (similar average probabilities).

### Mathematical Definition

$$\mathcal{L}_{\text{importance}} = \text{CV}(P_1, P_2, ..., P_E)^2$$

where CV is **coefficient of variation**:

$$\text{CV} = \frac{\sigma}{\mu} = \frac{\sqrt{\frac{1}{E}\sum_{i=1}^{E}(P_i - \bar{P})^2}}{\frac{1}{E}\sum_{i=1}^{E}P_i}$$

Since $\sum P_i = E$ (sum of means over probability distributions):

$$\bar{P} = \frac{1}{E}\sum_{i=1}^{E}P_i = 1$$

So:

$$\text{CV} = \sqrt{\frac{1}{E}\sum_{i=1}^{E}(P_i - 1)^2}$$

### Alternative Formulation: Variance

$$\mathcal{L}_{\text{importance}} = \text{Var}(P_1, ..., P_E) = \frac{1}{E}\sum_{i=1}^{E}(P_i - 1)^2$$

**Goal**: Minimize variance → all $P_i$ close to 1 (uniform importance)

### Step-by-Step Computation

**Input**: Router probabilities $G \in \mathbb{R}^{N \times E}$

**Step 1**: Compute mean probabilities
$$P_i = \frac{1}{N}\sum_{j=1}^{N}G_{ji}$$

**Step 2**: Compute variance
$$\sigma^2 = \frac{1}{E}\sum_{i=1}^{E}(P_i - 1)^2$$

**Step 3**: Importance loss
$$\mathcal{L}_{\text{importance}} = \sigma^2$$

### Numerical Example

**Mean probabilities from before**:
```
P = [0.231, 0.263, 0.263, 0.244]
```

**Compute variance**:
```
(P_0 - 1)^2 = (0.231 - 1)^2 = 0.591
(P_1 - 1)^2 = (0.263 - 1)^2 = 0.543
(P_2 - 1)^2 = (0.263 - 1)^2 = 0.543
(P_3 - 1)^2 = (0.244 - 1)^2 = 0.572

L_importance = (0.591 + 0.543 + 0.543 + 0.572) / 4 = 0.562
```

**Interpretation**: High variance → experts have different importance levels

---

## Router Z-Loss

### Motivation

**Problem**: Router logits can become very large (unbounded).

**Example**:
```
Router logits before training: [-0.5, 0.2, -0.1, 0.3]
After 1000 steps: [-50, 20, -10, 30]  ← Exploding!
```

This causes:
- Numerical instability
- Vanishing gradients in softmax
- Hard-to-tune training

### Mathematical Definition

**Router Z-loss** penalizes large logits:

$$\mathcal{L}_{\text{z}} = \frac{1}{N \times E} \sum_{i=1}^{N}\sum_{j=1}^{E} (\log \sum_{k=1}^{E} \exp(h_{ik}))^2$$

where $h_{ij}$ are router logits.

**Simplified** (commonly used):

$$\mathcal{L}_{\text{z}} = \frac{1}{N} \sum_{i=1}^{N} \left(\log \sum_{j=1}^{E} \exp(h_{ij})\right)^2$$

### Understanding the Formula

The term $\log \sum_{j=1}^{E} \exp(h_{ij})$ is the **log-sum-exp** (also called log-partition function).

**For well-behaved logits**: LSE ≈ log(E)

**For exploding logits**: LSE grows large

**Squaring**: Heavily penalizes large values

### Step-by-Step Computation

**Input**: Router logits $H \in \mathbb{R}^{N \times E}$

**Step 1**: Compute log-sum-exp for each token
$$z_i = \log \sum_{j=1}^{E} \exp(h_{ij})$$

**Step 2**: Square and average
$$\mathcal{L}_{\text{z}} = \frac{1}{N} \sum_{i=1}^{N} z_i^2$$

### Numerical Example

**Router logits**:
```
Token 0: [2.0, 0.5, -0.5, 0.0]
Token 1: [1.5, 1.0, 0.0, -0.5]
```

**Compute LSE**:
```
z_0 = log(exp(2.0) + exp(0.5) + exp(-0.5) + exp(0.0))
    = log(7.39 + 1.65 + 0.61 + 1.00)
    = log(10.65)
    = 2.37

z_1 = log(exp(1.5) + exp(1.0) + exp(0.0) + exp(-0.5))
    = log(4.48 + 2.72 + 1.00 + 0.61)
    = log(8.81)
    = 2.18
```

**Compute loss**:
```
L_z = (2.37^2 + 2.18^2) / 2
    = (5.62 + 4.75) / 2
    = 5.18
```

### Why It Works

**Gradient w.r.t. logits**:

$$\frac{\partial \mathcal{L}_{\text{z}}}{\partial h_{ij}} = 2z_i \cdot \text{softmax}(h_i)_j$$

This pushes logits toward 0, keeping them bounded.

---

## Combining Multiple Losses

### Total Loss Formulation

$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \alpha \cdot \mathcal{L}_{\text{balance}} + \beta \cdot \mathcal{L}_{\text{importance}} + \gamma \cdot \mathcal{L}_{\text{z}}$$

### Typical Hyperparameters

From literature and practice:

| Loss | Coefficient | Typical Range | Notes |
|------|-------------|---------------|-------|
| Task | 1.0 | Fixed | Main objective |
| Balance | 0.01 | 0.001 - 0.1 | Most important auxiliary |
| Importance | 0.01 | 0.001 - 0.05 | Optional, helps stability |
| Z-loss | 0.001 | 0.0001 - 0.01 | For numerical stability |

### Scheduling

**Option 1: Constant**
```python
alpha = 0.01  # Throughout training
```

**Option 2: Decay**
```python
alpha = alpha_max * (1 - step / total_steps)
```

Start high to enforce balance, gradually reduce to let task loss dominate.

**Option 3: Warmup then constant**
```python
if step < warmup_steps:
    alpha = alpha_max * (step / warmup_steps)
else:
    alpha = alpha_max
```

**Recommended: Start with constant, use decay if overfitting to auxiliary losses.**

---

## Metrics for MoE

### 1. Load Balance Metrics

**Balance Factor**:

$$B = \frac{\sum_{i=1}^{E} f_i^2}{(1/E) \sum_{i=1}^{E} f_i^2} = E \cdot \sum_{i=1}^{E} f_i^2$$

- Perfect balance: $B = 1$
- Higher values: worse balance
- Maximum: $B = E$ (all tokens to one expert)

**Coefficient of Variation (CV)**:

$$\text{CV} = \frac{\sigma(f)}{\mu(f)}$$

where $f = [f_1, ..., f_E]$.

Lower is better (more uniform distribution).

**Entropy**:

$$H(f) = -\sum_{i=1}^{E} f_i \log f_i$$

- Maximum: $H = \log E$ (perfect balance)
- Minimum: $H = 0$ (all to one expert)

### 2. Expert Utilization Metrics

**Active Experts** (per batch):

$$\text{Active} = \sum_{i=1}^{E} \mathbb{1}[f_i > 0]$$

**Fraction of Dead Experts**:

$$\text{Dead\%} = \frac{1}{E}\sum_{i=1}^{E} \mathbb{1}[f_i < \epsilon]$$

where $\epsilon$ is threshold (e.g., 0.001).

**Expert Capacity Utilization**:

$$\text{Utilization}_i = \frac{\text{tokens\_to\_expert}_i}{\text{capacity}_i}$$

Should be close to 1.0 (not wasting capacity, not overflowing).

### 3. Routing Quality Metrics

**Average Gate Concentration**:

$$\text{Concentration} = \frac{1}{N}\sum_{j=1}^{N} \max_i g_{ji}$$

High values (>0.8): Router is confident
Low values (<0.5): Router is uncertain

**Top-k Agreement** (stability):

Track how often same experts are selected across steps.

$$\text{Agreement} = \frac{1}{N}\sum_{j=1}^{N} |\text{TopK}_t(j) \cap \text{TopK}_{t-1}(j)|$$

### 4. Task Performance Metrics

**Perplexity** (language modeling):

$$\text{PPL} = \exp(\mathcal{L}_{\text{task}})$$

**Accuracy** (classification):

$$\text{Acc} = \frac{1}{N}\sum_{j=1}^{N} \mathbb{1}[\arg\max(\hat{y}_j) = y_j]$$

**Important**: Track both task metrics AND load balance metrics!

### 5. Efficiency Metrics

**Active Parameters Ratio**:

$$\text{Active\%} = \frac{k \times \text{expert\_size}}{E \times \text{expert\_size}} \times 100\% = \frac{k}{E} \times 100\%$$

For top-2 out of 8 experts: 25% active

**FLOPs Efficiency**:

$$\text{Efficiency} = \frac{\text{total\_parameters}}{\text{active\_parameters}}$$

Higher is better (more parameters for same compute).

---

## Implementation Guide

### Complete Training Loop with Auxiliary Losses

```python
def train_step(model, batch, optimizer, config):
    """
    Single training step with all auxiliary losses.
    
    Args:
        model: MoE model
        batch: (inputs, targets)
        optimizer: Optimizer
        config: Training configuration
        
    Returns:
        losses: Dictionary of all loss components
        metrics: Dictionary of metrics
    """
    inputs, targets = batch
    
    # Forward pass
    logits, router_outputs = model(inputs)
    
    # Task loss (e.g., cross-entropy)
    task_loss = F.cross_entropy(logits, targets)
    
    # Extract routing information
    gates = router_outputs['gates']  # (batch, seq_len, num_experts)
    top_k_indices = router_outputs['top_k_indices']  # (batch, seq_len, k)
    router_logits = router_outputs['logits']  # (batch, seq_len, num_experts)
    
    # Compute auxiliary losses
    balance_loss = compute_load_balance_loss(
        gates, top_k_indices, config.num_experts
    )
    
    importance_loss = compute_importance_loss(gates)
    
    z_loss = compute_router_z_loss(router_logits)
    
    # Total loss
    total_loss = (
        task_loss +
        config.alpha * balance_loss +
        config.beta * importance_loss +
        config.gamma * z_loss
    )
    
    # Backward pass
    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()
    
    # Compute metrics
    metrics = compute_moe_metrics(gates, top_k_indices, config.num_experts)
    
    # Prepare output
    losses = {
        'total': total_loss.item(),
        'task': task_loss.item(),
        'balance': balance_loss.item(),
        'importance': importance_loss.item(),
        'z_loss': z_loss.item()
    }
    
    return losses, metrics


def compute_load_balance_loss(gates, top_k_indices, num_experts):
    """
    Compute load balancing auxiliary loss.
    
    Args:
        gates: (batch, seq_len, num_experts) - gating probabilities
        top_k_indices: (batch, seq_len, k) - selected expert indices
        num_experts: Total number of experts
        
    Returns:
        Load balance loss (scalar)
    """
    batch, seq_len, num_experts_dim = gates.shape
    k = top_k_indices.shape[-1]
    num_tokens = batch * seq_len
    
    # Compute P_i (average probability for each expert)
    # Shape: (num_experts,)
    P = gates.mean(dim=[0, 1])
    
    # Compute f_i (fraction of tokens routed to each expert)
    # Shape: (num_experts,)
    f = torch.zeros(num_experts, device=gates.device)
    
    for i in range(num_experts):
        # Count tokens that have expert i in their top-k
        mask = (top_k_indices == i).any(dim=-1)  # (batch, seq_len)
        f[i] = mask.float().sum() / num_tokens
    
    # Normalize by k (since each token selects k experts)
    f = f / k
    
    # Load balance loss
    loss = num_experts * torch.sum(f * P)
    
    return loss


def compute_importance_loss(gates):
    """
    Compute importance auxiliary loss.
    
    Args:
        gates: (batch, seq_len, num_experts) - gating probabilities
        
    Returns:
        Importance loss (scalar)
    """
    # Compute mean probability per expert
    P = gates.mean(dim=[0, 1])  # (num_experts,)
    
    # Since sum of means over probability distribution = num_experts,
    # we want each P_i ≈ 1
    
    # Variance of P
    variance = torch.mean((P - 1.0) ** 2)
    
    return variance


def compute_router_z_loss(logits):
    """
    Compute router z-loss for numerical stability.
    
    Args:
        logits: (batch, seq_len, num_experts) - router logits
        
    Returns:
        Z-loss (scalar)
    """
    # Compute log-sum-exp for each token
    # logsumexp is numerically stable
    log_z = torch.logsumexp(logits, dim=-1)  # (batch, seq_len)
    
    # Square and average
    z_loss = torch.mean(log_z ** 2)
    
    return z_loss


def compute_moe_metrics(gates, top_k_indices, num_experts):
    """
    Compute comprehensive MoE metrics.
    
    Args:
        gates: (batch, seq_len, num_experts)
        top_k_indices: (batch, seq_len, k)
        num_experts: Total number of experts
        
    Returns:
        Dictionary of metrics
    """
    batch, seq_len, _ = gates.shape
    k = top_k_indices.shape[-1]
    num_tokens = batch * seq_len
    
    # Expert usage fractions
    f = torch.zeros(num_experts, device=gates.device)
    for i in range(num_experts):
        mask = (top_k_indices == i).any(dim=-1)
        f[i] = mask.float().sum() / num_tokens
    
    # Balance factor
    balance_factor = num_experts * torch.sum(f ** 2)
    
    # Coefficient of variation
    cv = torch.std(f) / (torch.mean(f) + 1e-8)
    
    # Entropy
    entropy = -torch.sum(f * torch.log(f + 1e-8))
    max_entropy = math.log(num_experts)
    
    # Active experts
    active_experts = torch.sum(f > 0).item()
    
    # Average gate concentration
    max_gates = torch.max(gates, dim=-1)[0]  # (batch, seq_len)
    avg_concentration = torch.mean(max_gates)
    
    # Expert counts
    expert_counts = torch.zeros(num_experts, device=gates.device)
    for i in range(num_experts):
        expert_counts[i] = (top_k_indices == i).any(dim=-1).float().sum()
    
    metrics = {
        'balance_factor': balance_factor.item(),
        'cv': cv.item(),
        'entropy': entropy.item(),
        'entropy_ratio': (entropy / max_entropy).item(),
        'active_experts': active_experts,
        'avg_concentration': avg_concentration.item(),
        'expert_counts': expert_counts.cpu().numpy(),
        'expert_usage': f.cpu().numpy()
    }
    
    return metrics
```

### Logging and Monitoring

```python
def log_moe_statistics(step, losses, metrics, writer):
    """
    Log MoE training statistics to TensorBoard.
    
    Args:
        step: Current training step
        losses: Dictionary of loss values
        metrics: Dictionary of metrics
        writer: TensorBoard writer
    """
    # Log losses
    for name, value in losses.items():
        writer.add_scalar(f'Loss/{name}', value, step)
    
    # Log balance metrics
    writer.add_scalar('Balance/factor', metrics['balance_factor'], step)
    writer.add_scalar('Balance/cv', metrics['cv'], step)
    writer.add_scalar('Balance/entropy', metrics['entropy'], step)
    writer.add_scalar('Balance/entropy_ratio', metrics['entropy_ratio'], step)
    
    # Log expert utilization
    writer.add_scalar('Experts/active', metrics['active_experts'], step)
    writer.add_scalar('Experts/avg_concentration', metrics['avg_concentration'], step)
    
    # Log expert usage histogram
    writer.add_histogram('Experts/usage', metrics['expert_usage'], step)
    writer.add_histogram('Experts/counts', metrics['expert_counts'], step)
    
    # Log individual expert usage as bar chart
    for i, usage in enumerate(metrics['expert_usage']):
        writer.add_scalar(f'Experts/usage_expert_{i}', usage, step)
```

### Early Warning System

```python
def check_routing_health(metrics, thresholds):
    """
    Check for routing problems and raise warnings.
    
    Args:
        metrics: Dictionary of metrics
        thresholds: Dictionary of threshold values
        
    Returns:
        List of warning messages
    """
    warnings = []
    
    # Check for severe load imbalance
    if metrics['balance_factor'] > thresholds['max_balance_factor']:
        warnings.append(
            f"Severe load imbalance detected! "
            f"Balance factor = {metrics['balance_factor']:.3f} "
            f"(threshold: {thresholds['max_balance_factor']})"
        )
    
    # Check for dead experts
    num_experts = len(metrics['expert_usage'])
    dead_experts = np.sum(metrics['expert_usage'] < thresholds['min_usage'])
    if dead_experts > thresholds['max_dead_experts']:
        warnings.append(
            f"{dead_experts} dead experts detected! "
            f"(threshold: {thresholds['max_dead_experts']})"
        )
    
    # Check for routing collapse
    max_usage = np.max(metrics['expert_usage'])
    if max_usage > thresholds['max_single_expert_usage']:
        warnings.append(
            f"Routing collapse! One expert handling {max_usage*100:.1f}% "
            f"(threshold: {thresholds['max_single_expert_usage']*100:.1f}%)"
        )
    
    # Check for low entropy (poor distribution)
    if metrics['entropy_ratio'] < thresholds['min_entropy_ratio']:
        warnings.append(
            f"Low routing entropy! Ratio = {metrics['entropy_ratio']:.3f} "
            f"(threshold: {thresholds['min_entropy_ratio']})"
        )
    
    return warnings


# Example thresholds
health_thresholds = {
    'max_balance_factor': 2.0,
    'min_usage': 0.001,
    'max_dead_experts': 2,
    'max_single_expert_usage': 0.5,
    'min_entropy_ratio': 0.7
}
```

---

## Practical Examples

### Example 1: Training Configuration

```python
# Configuration for 8-expert MoE with top-2 routing
config = {
    'num_experts': 8,
    'k': 2,
    'capacity_factor': 1.25,
    
    # Loss coefficients
    'alpha': 0.01,    # Load balance loss
    'beta': 0.01,     # Importance loss  
    'gamma': 0.001,   # Z-loss
    
    # Learning rate schedule for auxiliary losses
    'aux_loss_warmup_steps': 1000,
    'aux_loss_decay_steps': 10000,
}
```

### Example 2: Analyzing Results

```python
# After training, analyze expert specialization
def analyze_expert_specialization(model, dataset, num_experts):
    """
    Analyze what each expert specializes in.
    """
    expert_examples = {i: [] for i in range(num_experts)}
    
    for batch in dataset:
        outputs = model(batch['input'])
        top_experts = outputs['top_k_indices'][:, :, 0]  # Top-1 expert
        
        for token_idx, expert_idx in enumerate(top_experts.flatten()):
            expert_examples[expert_idx.item()].append(
                batch['input'][token_idx].item()
            )
    
    # Analyze each expert's examples
    for expert_id in range(num_experts):
        examples = expert_examples[expert_id]
        print(f"\nExpert {expert_id} ({len(examples)} tokens):")
        print(f"  Most common tokens: {Counter(examples).most_common(10)}")
```

### Example 3: Debugging Imbalance

```python
# If you see load imbalance, try these fixes

# Fix 1: Increase balance loss coefficient
config['alpha'] = 0.05  # Was 0.01

# Fix 2: Add noise to routing
def add_routing_noise(logits, noise_std=0.1):
    noise = torch.randn_like(logits) * noise_std
    return logits + noise

# Fix 3: Use expert dropout
def expert_dropout(expert_indices, dropout_rate=0.1):
    """Randomly disable some expert selections."""
    mask = torch.rand_like(expert_indices.float()) > dropout_rate
    return expert_indices * mask + (1 - mask) * torch.randint_like(expert_indices, 0, num_experts)

# Fix 4: Periodic expert reset
if step % 5000 == 0:
    # Re-initialize poorly performing experts
    for i in range(num_experts):
        if expert_usage[i] < 0.01:
            model.experts[i].reset_parameters()
```

---

## Debugging Load Imbalance

### Common Patterns and Solutions

**Pattern 1: One Expert Dominates from Start**

```
Step 0:   [0.25, 0.25, 0.25, 0.25]  ← Balanced
Step 100: [0.60, 0.20, 0.15, 0.05]  ← Imbalance starts
Step 500: [0.95, 0.03, 0.01, 0.01]  ← Collapsed
```

**Solutions**:
- Increase α (balance loss coefficient)
- Add stronger noise to routing
- Use smaller learning rate for router

**Pattern 2: Gradual Specialization**

```
Step 0:    [0.25, 0.25, 0.25, 0.25]
Step 1000: [0.30, 0.28, 0.24, 0.18]  ← Slight imbalance
Step 5000: [0.35, 0.32, 0.20, 0.13]  ← Growing
Step 10000: [0.50, 0.30, 0.15, 0.05] ← Significant
```

**Solutions**:
- This might be OK! Experts specializing is good
- Only intervene if some experts die completely
- Monitor task performance, not just balance

**Pattern 3: Dead Experts**

```
Expert usage: [0.20, 0.19, 0.21, 0.18, 0.00, 0.22, 0.00, 0.00]
                                         ↑           ↑       ↑
                                      Dead experts
```

**Solutions**:
- Re-initialize dead experts periodically
- Use expert choice routing instead
- Ensure auxiliary losses are active

### Monitoring Dashboard

**Essential metrics to track**:

```python
# Every N steps, print summary
if step % 100 == 0:
    print(f"\nStep {step}")
    print(f"Task Loss: {task_loss:.4f}")
    print(f"Balance Loss: {balance_loss:.4f}")
    print(f"Expert Usage: {expert_usage}")
    print(f"Balance Factor: {balance_factor:.3f}")
    print(f"Active Experts: {active_experts}/{num_experts}")
    print(f"Entropy Ratio: {entropy_ratio:.3f}")
```

---

## Key Takeaways

### Critical Points

1. **Always use load balance loss** with sparse routing
   - Coefficient: 0.01 is good starting point
   - Monitor and adjust based on metrics

2. **Track both task AND balance metrics**
   - Don't just look at accuracy/perplexity
   - Watch for routing collapse

3. **Multiple auxiliary losses work together**
   - Balance loss: Equal token distribution
   - Importance loss: Equal importance
   - Z-loss: Numerical stability

4. **Acceptable trade-offs**
   - Small task performance hit (1-2%) is OK
   - For better efficiency (3-10x parameter increase)

5. **Warning signs**
   - Balance factor > 2.0: Severe imbalance
   - Dead experts > 20%: Fix routing
   - Entropy ratio < 0.5: Near collapse

### Recommended Configuration

```python
# Conservative (prioritize balance)
alpha = 0.05
beta = 0.02
gamma = 0.001

# Balanced (good default)
alpha = 0.01
beta = 0.01
gamma = 0.001

# Aggressive (prioritize task performance)
alpha = 0.001
beta = 0.0
gamma = 0.0001
```

---

